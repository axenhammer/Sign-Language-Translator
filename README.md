# Universal Sign Language Translator
[![Language](https://img.shields.io/badge/language-python-blue.svg?style=flat)](https://www.python.org)

## Introduction
We aim to raise our AI model using the Machine Learning, Image Processing which involved repeatedly gesturing in front of a camera to teach the system the fundamentals of sign language. This is to combat the differences between various Countryâ€™s sign languages and their regional dialects without compromising on accuracy while giving way to crowd-sourcing.


## Intermediate Outputs
#### RAW Feed (1920x1080 @ 60 fps)
<img src="/docs/gifs/rawf_everyone.gif" width="360"/><img src="/docs/gifs/rawf_kk.gif" width="360"/>

#### Extraction of skin tones (Removal of unwanted entities)
<img src="/docs/gifs/skin_ext_everyone.gif" width="360"/><img src="/docs/gifs/skin_kk.gif" width="360"/>

#### Canny Edge Detection to extract only perimeter of change
<img src="/docs/gifs/edges_everyone.gif" width="360"/><img src="/docs/gifs/edges_kk.gif" width="360"/>


## Team/Organisation
* **Team Axenhammer** - [Axenhammer](https://github.com/axenhammer)


## Authors
* **Krishna Alagiri** - [KrishnaAlagiri](https://github.com/KrishnaAlagiri/)
* **Mahalakshumi V** - [maha2000](https://github.com/maha2000/)
* **Ajay Krishnan** - [ajaykrishnan23](https://github.com/ajaykrishnan23/)
* **Saiharshith** - [harshith2000](https://github.com/harshith2000/)
